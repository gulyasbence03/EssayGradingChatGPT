{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEHxxAPiLz3lvCWFtrfeed",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulyasbence03/EssayGradingChatGPT/blob/main/EssayGrading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#23_05d  Automated Essay Scorer:\n",
        "    Design a system that scores essays based on factors like grammar, coherence, and vocabulary.\n",
        "    Use Natural Language Processing techniques and get assistance with libraries like NLTK or spaCy."
      ],
      "metadata": {
        "id": "ww5gGAeajTjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "!pip install language-tool-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrwHgh5zn4BZ",
        "outputId": "683ccc1d-2f9f-43f6-9ae9-9b0d8f4fa81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting language-tool-python\n",
            "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from language-tool-python) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from language-tool-python) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->language-tool-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->language-tool-python) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->language-tool-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->language-tool-python) (2023.11.17)\n",
            "Installing collected packages: language-tool-python\n",
            "Successfully installed language-tool-python-2.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import language_tool_python\n",
        "\n",
        "def tokenize_and_filter_punctuation(text):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if len(token) > 1 or token.isalnum() or token in {\"'\", '\"', '`'}]\n",
        "    tokens = [token[:-2] if token.endswith(\"'s\") else token for token in tokens]\n",
        "    tokens = [token.replace('\"', '') for token in tokens]\n",
        "    return tokens\n",
        "\n",
        "def filter_common_words(words):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return filtered_words\n",
        "\n",
        "def calculate_unique_word_count(text):\n",
        "    print(\"Checking Vocabulary...\")\n",
        "    words = tokenize_and_filter_punctuation(text)\n",
        "    filtered_words = filter_common_words(words)\n",
        "    filtered_words = [word for word in filtered_words if word != '']\n",
        "    unique_words = set(filtered_words)\n",
        "    max_unique_word_count = len(filtered_words)\n",
        "\n",
        "    if max_unique_word_count == 0:\n",
        "        unique_word_count_grade = 1\n",
        "    else:\n",
        "        unique_word_count_ratio = len(unique_words) / max_unique_word_count\n",
        "        if unique_word_count_ratio >= 0.75:\n",
        "            unique_word_count_grade = 5\n",
        "        elif 0.75 > unique_word_count_ratio >= 0.60:\n",
        "            unique_word_count_grade = 4\n",
        "        elif 0.60 > unique_word_count_ratio >= 0.45:\n",
        "            unique_word_count_grade = 3\n",
        "        elif 0.45 > unique_word_count_ratio >= 0.30:\n",
        "            unique_word_count_grade = 2\n",
        "        else:\n",
        "            unique_word_count_grade = 1\n",
        "\n",
        "    print(\"Vocabulary Check Complete\")\n",
        "    return unique_word_count_grade\n",
        "\n",
        "def is_related(word1, word2):\n",
        "    synsets1 = wordnet.synsets(word1)\n",
        "    synsets2 = wordnet.synsets(word2)\n",
        "\n",
        "    for synset1 in synsets1:\n",
        "        for synset2 in synsets2:\n",
        "            if synset1.wup_similarity(synset2) is not None and synset1.wup_similarity(synset2) > 0.6:\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def check_coherence(text):\n",
        "    print(\"Checking Coherence...\")\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if len(token) > 1 and token not in stopwords.words('english')]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    coherence_score = 0\n",
        "\n",
        "    # Calculate the maximum possible coherence score based on the number of adjacent word pairs\n",
        "    max_coherence_score = max(len(tokens) - 1, 1)\n",
        "\n",
        "    for i in range(len(pos_tags) - 1):\n",
        "        word1, pos1 = pos_tags[i]\n",
        "        word2, pos2 = pos_tags[i + 1]\n",
        "\n",
        "        if is_related(word1, word2) and pos1 == pos2:\n",
        "            coherence_score += 1\n",
        "\n",
        "    # Calculate coherence grade relative to the essay length\n",
        "    coherence_ratio = coherence_score / max_coherence_score\n",
        "\n",
        "    if coherence_ratio >= 0.06:\n",
        "        coherence_grade = 5\n",
        "    elif 0.06 > coherence_ratio >= 0.04:\n",
        "        coherence_grade = 4\n",
        "    elif 0.04 > coherence_ratio >= 0.02:\n",
        "        coherence_grade = 3\n",
        "    elif 0.02 > coherence_ratio >= 0.01:\n",
        "        coherence_grade = 2\n",
        "    else:\n",
        "        coherence_grade = 1\n",
        "\n",
        "    print(\"Coherence Check Complete.\")\n",
        "    return coherence_grade\n",
        "\n",
        "\n",
        "def provide_feedback(vocab_grade, coherence_grade, grammar_grade):\n",
        "    if vocab_grade < 5:\n",
        "        print(\"*** The essay could be improved with a richer vocabulary. ***\")\n",
        "\n",
        "    if coherence_grade < 5:\n",
        "        print(\"*** The essay lacks coherence. Consider improving the flow between sentences and paragraphs. ***\")\n",
        "\n",
        "    if grammar_grade < 5:\n",
        "        print(\"*** The essay contains grammar issues. Consider reviewing and correcting them. ***\")\n",
        "\n",
        "def check_grammar(text):\n",
        "    print(\"Checking Grammar...\")\n",
        "    tool = language_tool_python.LanguageTool('en-US')\n",
        "    matches = tool.check(text)\n",
        "    return matches\n",
        "\n",
        "def assign_grammar_grade(grammar_issues, essay_length):\n",
        "    total_issues = len(grammar_issues)\n",
        "\n",
        "    # Calculate the ratio of grammar issues relative to the essay length\n",
        "    issues_ratio = total_issues / essay_length\n",
        "\n",
        "    print(\"Grammar Check Complete.\")\n",
        "    # Adjust the thresholds based on the ratio\n",
        "    if issues_ratio <= 0.01:\n",
        "        return 5  # Perfect grammar\n",
        "    elif issues_ratio <= 0.02:\n",
        "        return 4  # Minor issues\n",
        "    elif issues_ratio <= 0.03:\n",
        "        return 3  # Moderate issues\n",
        "    elif issues_ratio <= 0.04:\n",
        "        return 2  # Substantial issues\n",
        "    else:\n",
        "        return 1  # Numerous issues\n",
        "\n",
        "def calculate_overall_grade(grammar_grade, vocab_grade, coherence_grade):\n",
        "    overall_grade = (grammar_grade + vocab_grade + coherence_grade) / 3\n",
        "    return round(overall_grade)\n",
        "\n",
        "good_essay = \"\"\"\n",
        "To begin with pollution and damage to the environment is the most serious and difficult problem for countries of all over the world. Scientists of different countries predict a global ecocatastrophe if people won’t change their attitude to our planet.\n",
        "\n",
        "First of all a huge damage to the environment brings a transport. People can’t imagine their living without cars, buses, trains, ships and planes. But it’s an open secret that one of disadvantage of these accustomed things is harmful exhaust. Needless to say that use of environment friendly engines helps us to save atmosphere from pollution.\n",
        "\n",
        "In addition to this our rivers and seas are in not less danger situation. It’s a fact of common knowledge that numerous factories and plants pour off their waste to ponds. Obviously that cleaning manufacturing water helps to avoid extinction of ocean residents.\n",
        "\n",
        "Apart from this I’m inclined to believe that every person can and must contribute to solving this important problem. Doing a little steps for protection our environment every day we will be able to save our Earth. And it’s a task of each of us.\n",
        "\"\"\"\n",
        "\n",
        "vocab_grade_good = calculate_unique_word_count(good_essay)\n",
        "print(f\"Vocab: {vocab_grade_good}\")\n",
        "\n",
        "coherence_grade_good = check_coherence(good_essay)\n",
        "print(f\"Coherence: {coherence_grade_good}\")\n",
        "\n",
        "grammar_issues_good = check_grammar(good_essay)\n",
        "essay_length = len(good_essay.split())\n",
        "grammar_grade_good = assign_grammar_grade(grammar_issues_good, essay_length)\n",
        "print(f\"Grammar: {grammar_grade_good}\")\n",
        "\n",
        "overall_grade_good = calculate_overall_grade(grammar_grade_good, vocab_grade_good, coherence_grade_good)\n",
        "print(f\"Overall essay grade: {overall_grade_good}\")\n",
        "\n",
        "provide_feedback(vocab_grade_good, coherence_grade_good, grammar_grade_good)\n",
        "\n",
        "# Examples from : https://engxam.com/handbook/essays-sample-answers-comments-b2-first-fce/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R8PztRyxv_x",
        "outputId": "18a4a4b2-6c06-464c-dd45-040d9d8b2ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking Vocabulary...\n",
            "Vocabulary Check Complete\n",
            "Vocab: 5\n",
            "Checking Coherence...\n",
            "Coherence Check Complete.\n",
            "Coherence: 5\n",
            "Checking Grammar...\n",
            "Grammar Check Complete.\n",
            "Grammar: 3\n",
            "Overall essay grade: 4\n",
            "*** The essay contains grammar issues. Consider reviewing and correcting them. ***\n"
          ]
        }
      ]
    }
  ]
}